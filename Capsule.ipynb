{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import json\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [28,28]\n",
    "\n",
    "X = tf.placeholder(shape=[None, input_dim[0],input_dim[1], 1], dtype=tf.float32, name=\"X\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsule(input_,input_caps,input_n_dims,ouput_n_caps,ouput_n_dims,name):\n",
    "    init_sigma = 0.01\n",
    " \n",
    "    W_init = tf.random_normal(\n",
    "    shape=(1, input_caps, ouput_n_caps, ouput_n_dims, input_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=(str(name) + \"_W_init\"))\n",
    "    \n",
    "    W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=name + \"_W_tiled\")\n",
    "\n",
    "    print(W_tiled)\n",
    "    print(input_)\n",
    "\n",
    "    caps2_predicted = tf.matmul(W_tiled, input_,\n",
    "                                name=name + \"_predicted\")\n",
    "    caps2_predicted\n",
    "\n",
    "    raw_weights = tf.zeros([batch_size, input_caps, ouput_n_caps, 1, 1],\n",
    "                           dtype=np.float32, name=name + \"_raw_weights\")\n",
    "\n",
    "    routing_weights = tf.nn.softmax(raw_weights, dim=2, name=name + \"_routing_weights\")\n",
    "\n",
    "    weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                       name=name + \"_weighted_predictions\")\n",
    "    weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                                 name=name + \"_weighted_sum\")\n",
    "\n",
    "    caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                                  name=name + \"_caps2_output_round_1\")\n",
    "\n",
    "    caps2_output_round_1\n",
    "\n",
    "\n",
    "    caps2_output_round_1_tiled = tf.tile(\n",
    "        caps2_output_round_1, [1, input_caps, 1, 1, 1],\n",
    "        name=name + \"_caps2_output_round_1_tiled\")\n",
    "\n",
    "    agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                          transpose_a=True, name=name + \"_agreement\")\n",
    "\n",
    "    raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                                 name=name + \"_raw_weights_round_2\")\n",
    "\n",
    "\n",
    "    routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                            dim=2,\n",
    "                                            name=name + \"_routing_weights_round_2\")\n",
    "    weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                               caps2_predicted,\n",
    "                                               name=name + \"_weighted_predictions_round_2\")\n",
    "    weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                         axis=1, keep_dims=True,\n",
    "                                         name=name + \"_weighted_sum_round_2\")\n",
    "    caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                                  axis=-2,\n",
    "                                  name=name+\"_output_round_2\")\n",
    "\n",
    "    caps2_output = caps2_output_round_2\n",
    "    return caps2_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_maps = 8\n",
    "caps1_n_dims = 8\n",
    "\n",
    "num_classes =10\n",
    "\n",
    "\n",
    "caps2_n_dims = 8\n",
    "caps2_n_caps = 32\n",
    "\n",
    "caps3_n_caps = num_classes\n",
    "caps3_n_dims = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", filters = 32, \n",
    "                         kernel_size = 9,strides = 1,padding = \"valid\", activation = tf.nn.relu)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", filters = caps1_n_maps * caps1_n_dims,\n",
    "                         kernel_size = 9,strides = 2, padding = \"valid\",activation = tf.nn.relu)\n",
    "\n",
    "caps1_n_caps = caps1_n_maps * conv2.get_shape().as_list()[1]  * conv2.get_shape().as_list()[2]  # 1152 primary capsules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"caps1_raw:0\", shape=(?, 288, 8), dtype=float32)\n",
      "Tensor(\"caps1_output_tiled:0\", shape=(?, 288, 32, 8, 1), dtype=float32)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "print(caps1_raw)\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "#1152, 10, 16, 1\n",
    "print(caps1_output_tiled)\n",
    "\n",
    "print(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caps2\n",
      "Tensor(\"caps2_W_tiled:0\", shape=(?, 288, 32, 8, 8), dtype=float32)\n",
      "Tensor(\"caps1_output_tiled:0\", shape=(?, 288, 32, 8, 1), dtype=float32)\n",
      " \n",
      "Tensor(\"caps2_output_round_2/mul:0\", shape=(?, 1, 32, 8, 1), dtype=float32)\n",
      "Tensor(\"caps2_output_tiled:0\", shape=(?, 32, 10, 8, 1), dtype=float32)\n",
      "\n",
      "caps3\n",
      "Tensor(\"caps3_W_tiled:0\", shape=(?, 32, 10, 8, 8), dtype=float32)\n",
      "Tensor(\"caps2_output_tiled:0\", shape=(?, 32, 10, 8, 1), dtype=float32)\n",
      "\n",
      "Tensor(\"caps3_output_round_2/mul:0\", shape=(?, 1, 10, 8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"caps2\")\n",
    "caps2_output = capsule(caps1_output_tiled,caps1_n_caps,caps1_n_dims,caps2_n_caps,caps2_n_dims,name = \"caps2\")\n",
    "print(\" \")\n",
    "print(caps2_output)\n",
    "\n",
    "caps2_raw = tf.reshape(caps2_output, [-1, caps2_n_caps, caps2_n_dims],\n",
    "                       name=\"caps2_raw\")\n",
    "caps2_output_expanded = tf.expand_dims(caps2_raw, -1,\n",
    "                                       name=\"caps2_output_expanded\")\n",
    "\n",
    "caps2_output_tile = tf.expand_dims(caps2_output_expanded, 2,\n",
    "                                   name=\"caps2_output_tile\")\n",
    "\n",
    "caps2_output_tiled = tf.tile(caps2_output_tile, [1, 1, caps3_n_caps, 1, 1],\n",
    "                             name=\"caps2_output_tiled\")\n",
    "print(caps2_output_tiled)\n",
    "\n",
    "print(\"\")\n",
    "print(\"caps3\")\n",
    "\n",
    "caps3_output = capsule(caps2_output_tiled,caps2_n_caps,caps2_n_dims,caps3_n_caps,caps3_n_dims,name = \"caps3\")\n",
    "\n",
    "output = caps3_output\n",
    "print(\"\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328350, 100)\n"
     ]
    }
   ],
   "source": [
    "def condition(input, counter):\n",
    "    return tf.less(counter, 100)\n",
    "\n",
    "def loop_body(input, counter):\n",
    "    output = tf.add(input, tf.square(counter))\n",
    "    return output, tf.add(counter, 1)\n",
    "\n",
    "with tf.name_scope(\"compute_sum_of_squares\"):\n",
    "    counter = tf.constant(1)\n",
    "    sum_of_squares = tf.constant(0)\n",
    "\n",
    "    result = tf.while_loop(condition, loop_body, [sum_of_squares, counter])#,swap_memory=True)\n",
    "    \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "    \n",
    "y_proba = safe_norm(output, axis=-2, name=\"y_proba\")\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(caps,num_caps):\n",
    "    T = tf.one_hot(y, depth=num_caps, name=\"T\")\n",
    "    \n",
    "    caps_output_norm = safe_norm(caps, axis=-2, keep_dims=True,\n",
    "                                  name=\"caps_output_norm\")\n",
    "\n",
    "    present_error_raw = tf.square(tf.maximum(0., m_plus - caps_output_norm),\n",
    "                                  name=\"present_error_raw\")\n",
    "    present_error = tf.reshape(present_error_raw, shape=(-1, num_caps),\n",
    "                               name=\"present_error\")\n",
    "\n",
    "    absent_error_raw = tf.square(tf.maximum(0., caps_output_norm - m_minus),\n",
    "                                 name=\"absent_error_raw\")\n",
    "    absent_error = tf.reshape(absent_error_raw, shape=(-1, num_caps),\n",
    "                              name=\"absent_error\")\n",
    "    L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "               name=\"L\")\n",
    "\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "    return margin_loss\n",
    "margin_loss = tf.add(loss(output,num_classes) , loss(caps2_output,caps2_n_caps))\n",
    "#margin_loss =loss(caps2_output,caps2_n_caps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"reconstruction_mask_reshaped:0\", shape=(?, 1, 10, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=num_classes,\n",
    "                                 name=\"reconstructone_hotone_hotion_mask\")\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, num_classes, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "print(reconstruction_mask_reshaped)\n",
    "\n",
    "caps_output_masked = tf.multiply(\n",
    "    output, reconstruction_mask_reshaped,\n",
    "    name=\"caps_output_masked\")\n",
    "\n",
    "\n",
    "decoder_input = tf.reshape(caps_output_masked,\n",
    "                           [-1, caps3_n_caps * caps3_n_dims],\n",
    "                           name=\"decoder_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = input_dim[0] * input_dim[1]\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_sum(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training MNIST\n",
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "Iteration: 42/1100 (3.8%)  Loss: 0.63987"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-78b9aad72fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                 feed_dict={X: X_batch.reshape([-1, input_dim[0], input_dim[1], 1]),\n\u001b[1;32m     30\u001b[0m                            \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                            mask_with_labels: True})\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"  predicted : {}  real : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training MNIST\")\n",
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
    "\n",
    "n_iterations_validation = 100#mnist.train.num_examples // batch_size\n",
    "\n",
    "\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "    predicted = \"\"\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "           \n",
    "            _, loss_train,pred,real = sess.run(\n",
    "                [training_op, loss,y_pred,y],\n",
    "                feed_dict={X: X_batch.reshape([-1, input_dim[0], input_dim[1], 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            if(iteration % 50 == 0):\n",
    "                predicted = \"  predicted : {}  real : {}\".format(pred[0:5],real[0:5])\n",
    "                \n",
    "            print((\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\"+predicted).format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "               \n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, input_dim[0], input_dim[1], 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "sample_images = mnist.test.images[:n_samples].reshape([-1, input_dim[0], input_dim[1], 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "            [caps2_output, decoder_output, y_pred],\n",
    "            feed_dict={X: sample_images,\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_images = sample_images.reshape(-1, input_dim[0], input_dim[1])\n",
    "reconstructions = decoder_output_value.reshape([-1, input_dim[0], input_dim[1]])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "sample_images = sample_images.reshape(-1, input_dim[0], input_dim[1])\n",
    "reconstructions = decoder_output_value.reshape([-1, input_dim[0], input_dim[1]])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
