{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from CapsLayer import Capsule,squash,margin_loss,safe_norm,bridge\n",
    "import json\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [28,28]\n",
    "\n",
    "X = tf.placeholder(shape=[None, input_dim[0],input_dim[1], 1], dtype=tf.float32, name=\"X\")\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_maps = 16\n",
    "caps1_n_dims = 16\n",
    "\n",
    "num_classes =10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2/BiasAdd:0\", shape=(?, 6, 6, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", filters = 256, \n",
    "                         kernel_size = 9,strides = 1,padding = \"valid\", activation = None)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", filters = caps1_n_maps * caps1_n_dims,\n",
    "                         kernel_size = 9,strides = 2, padding = \"valid\",activation = None)\n",
    "\n",
    "caps1_n_caps = caps1_n_maps * conv2.get_shape().as_list()[1]  * conv2.get_shape().as_list()[2] \n",
    "\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"caps2_W_tiled:0\", shape=(?, 576, 64, 16, 16), dtype=float32)\n",
      "Tensor(\"caps_bridge:0\", shape=(?, 576, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps2_predicted:0\", shape=(?, 576, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps2_routing_weights:0\", shape=(?, 576, 64, 1, 1), dtype=float32)\n",
      "Tensor(\"caps2_weighted_predictions:0\", shape=(?, 576, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps2_weighted_sum:0\", shape=(?, 1, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps2_caps_output_round_1/mul:0\", shape=(?, 1, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps2_caps_output_round_1_tiled:0\", shape=(?, 576, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps2_agreement:0\", shape=(?, 576, 64, 1, 1), dtype=float32)\n",
      "Tensor(\"caps2_weighted_predictions_round_2:0\", shape=(?, 576, 64, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_W_tiled:0\", shape=(?, 64, 10, 16, 16), dtype=float32)\n",
      "Tensor(\"caps2_bridge:0\", shape=(?, 64, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_predicted:0\", shape=(?, 64, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_routing_weights:0\", shape=(?, 64, 10, 1, 1), dtype=float32)\n",
      "Tensor(\"caps3_weighted_predictions:0\", shape=(?, 64, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_weighted_sum:0\", shape=(?, 1, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_caps_output_round_1/mul:0\", shape=(?, 1, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_caps_output_round_1_tiled:0\", shape=(?, 64, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps3_agreement:0\", shape=(?, 64, 10, 1, 1), dtype=float32)\n",
      "Tensor(\"caps3_weighted_predictions_round_2:0\", shape=(?, 64, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_W_tiled:0\", shape=(?, 10, 10, 16, 16), dtype=float32)\n",
      "Tensor(\"caps3_bridge:0\", shape=(?, 10, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_predicted:0\", shape=(?, 10, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_routing_weights:0\", shape=(?, 10, 10, 1, 1), dtype=float32)\n",
      "Tensor(\"caps4_weighted_predictions:0\", shape=(?, 10, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_weighted_sum:0\", shape=(?, 1, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_caps_output_round_1/mul:0\", shape=(?, 1, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_caps_output_round_1_tiled:0\", shape=(?, 10, 10, 16, 1), dtype=float32)\n",
      "Tensor(\"caps4_agreement:0\", shape=(?, 10, 10, 1, 1), dtype=float32)\n",
      "Tensor(\"caps4_weighted_predictions_round_2:0\", shape=(?, 10, 10, 16, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "caps2 = Capsule(num_caps=64, caps_dims=16, name=\"caps2\")\n",
    "caps3 = Capsule(num_caps=num_classes, caps_dims=16, name=\"caps3\")\n",
    "caps4 = Capsule(num_caps=num_classes, caps_dims=16, name=\"caps4\")\n",
    "\n",
    "caps1_bridge =bridge(conv2,caps1_n_caps,caps1_n_dims,caps2)\n",
    "\n",
    "caps2_output = caps2.capsule(caps1_bridge,caps1_n_caps,caps1_n_dims,tf.shape(X)[0],init_sigma = 0.5)\n",
    "caps2_bridge = caps2.bridge(caps2_output,caps3)\n",
    "\n",
    "caps3_output = caps3.capsule(caps2_bridge,caps2.num_caps,caps2.caps_dims,tf.shape(X)[0],init_sigma = 0.5)\n",
    "caps3_bridge = caps3.bridge(caps3_output,caps4)\n",
    "\n",
    "caps4_output = caps4.capsule(caps3_bridge,caps3.num_caps,caps3.caps_dims,tf.shape(X)[0],init_sigma = 0.5)\n",
    "\n",
    "output = caps4_output\n",
    "output_caps = caps4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = safe_norm(output, axis=-2, name=\"y_proba\")\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=num_classes,\n",
    "                                 name=\"reconstructone_hotone_hotion_mask\")\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, num_classes, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps_output_masked = tf.multiply(\n",
    "    output, reconstruction_mask_reshaped,\n",
    "    name=\"caps_output_masked\")\n",
    "\n",
    "\n",
    "decoder_input = tf.reshape(caps_output_masked,\n",
    "                           [-1, output_caps.num_caps * output_caps.caps_dims],\n",
    "                           name=\"decoder_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = input_dim[0] * input_dim[1]\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_sum(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"absent_error:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss(output,num_classes,y), alpha * reconstruction_loss, name=\"loss\")\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training MNIST\n",
      "Epoch: 1  Val accuracy: 96.8800%  Loss: 0.482650 (improved)5 8 6 0 7]  real : [5 8 6 0 7]\n",
      "Iteration: 2/1100 (0.2%)  Loss: 0.42756  predicted : [6 0 6 7 1]  real : [6 0 6 7 1]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a084cb744875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 feed_dict={X: X_batch.reshape([-1, input_dim[0], input_dim[1], 1]),\n\u001b[0;32m---> 30\u001b[0;31m                            y: y_batch})\n\u001b[0m\u001b[1;32m     31\u001b[0m                            \u001b[0;31m#mask_with_labels: True})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training MNIST\")\n",
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
    "\n",
    "n_iterations_validation = 100#mnist.train.num_examples // batch_size\n",
    "\n",
    "\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "#    init.run()\n",
    "    predicted = \"\"\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "           #sess.graph.get_tensor_by_name(\"caps4_raw_weights:0\")\n",
    "            _, loss_train,pred,real = sess.run(\n",
    "                [training_op, loss,y_pred,y],\n",
    "                feed_dict={X: X_batch.reshape([-1, input_dim[0], input_dim[1], 1]),\n",
    "                           y: y_batch})\n",
    "                           #mask_with_labels: True})\n",
    "            if(iteration % 2 == 0):\n",
    "                #print(\"test1 : \",test_1)\n",
    "                #print(\"test2 : \",test_2)\n",
    "                predicted = \"  predicted : {}  real : {}\".format(pred[0:5],real[0:5])\n",
    "            print((\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\"+predicted).format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "               \n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, input_dim[0], input_dim[1], 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_samples = 5\n",
    "\n",
    "sample_images = mnist.test.images[:n_samples].reshape([-1, 28, 28, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "            [caps2_output, decoder_output, y_pred],\n",
    "            feed_dict={X: sample_images,\n",
    "                       y: np.array([], dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACPCAYAAADeIl6VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIAIJFMAAAAR/h/GAH4THTWYVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28d491eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACPCAYAAADeIl6VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28d489efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_images = sample_images.reshape(-1, 28, 28)\n",
    "reconstructions = decoder_output_value.reshape([-1, 28, 28])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
