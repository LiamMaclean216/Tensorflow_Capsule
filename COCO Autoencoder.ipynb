{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import CapsLayer as cp\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and resize from coco\n",
    "shape=[64,64,3]\n",
    "def gen_data(batch_size,shape=[256,256,3],path='data/unlabeled2017/'):\n",
    "    num_of_digits = 12\n",
    "    \n",
    "    out = np.zeros([batch_size,shape[0],shape[1],shape[2]])\n",
    "    b_num = 0\n",
    "    idx = 1\n",
    "    while True:\n",
    "        f = \"0\"*(12-len(str(idx)))+str(idx)+\".jpg\"\n",
    "        if b_num < batch_size:\n",
    "            img = cv2.imread(path+f)\n",
    "           # print(np.array(img[0]).shape)\n",
    "            if(np.array(img).shape==()):\n",
    "                if idx > 123392 // batch_size:\n",
    "                    break\n",
    "                idx+=1\n",
    "                continue\n",
    "        \n",
    "            out[b_num] =  cv2.resize(img,(shape[0],shape[1]))\n",
    "            \n",
    "            b_num+=1\n",
    "        else:\n",
    "            b_num=0\n",
    "            yield out\n",
    "        \n",
    "        idx+=1\n",
    "        if idx > 123392 // batch_size:\n",
    "            break\n",
    "\n",
    "def gen_data(batch_size,shape=[256,256,3],path='data/unlabeled2017/'):\n",
    "    out = np.zeros([batch_size,shape[0],shape[1],shape[2]])\n",
    "    b_num = 0\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if b_num < batch_size:\n",
    "            \n",
    "            out[b_num] = cv2.resize(cv2.imread(path+f),(shape[0],shape[1]))\n",
    "            b_num+=1\n",
    "        else:\n",
    "            b_num = 0\n",
    "            yield out\n",
    "    \n",
    "#data = gen_data(5,shape=shape)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(shape=[None, shape[0],shape[1], shape[2]], dtype=tf.float32, name=\"x_input\")\n",
    "Y = tf.placeholder(shape=[None, shape[0],shape[1], shape[2]], dtype=tf.float32, name=\"y_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "e_conv1 = tf.layers.conv2d(X, name=\"e_conv1\", filters = 32, \n",
    "                             kernel_size = 9,strides = 2,padding = \"valid\", activation = tf.nn.relu)\n",
    "e_conv2 = cp.conv_to_caps(e_conv1,num_maps=32,caps_dims=1,kernel_size = 9,strides = 2\n",
    "                        ,name=\"e_conv2\", activation = tf.nn.relu)\n",
    "caps1 = cp.capsule(e_conv2,num_caps=1200,caps_dims=2,batch_size=tf.shape(X)[0],name=\"e_caps1\")\n",
    "\n",
    "caps_bridge = tf.reshape(caps1,[tf.shape(caps1)[0],caps1.shape[1],caps1.shape[2],1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"e_conv1/Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"e_conv2reshape:0\", shape=(?, 3200, 1), dtype=float32) Tensor(\"e_caps1/Squeeze:0\", shape=(?, 1200, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(e_conv1)\n",
    "print(e_conv2,caps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "d_conv1 = tf.layers.conv2d(caps_bridge, name=\"d_conv1\", filters = 16, \n",
    "                             kernel_size = 1,strides = 1,padding = \"valid\", activation = tf.nn.relu)\n",
    "d_conv2 = tf.layers.conv2d(d_conv1, name=\"d_conv2\", filters = 32, \n",
    "                             kernel_size = 1,strides = 1,padding = \"valid\", activation = tf.nn.relu)\n",
    "d_conv3 = tf.layers.conv2d(d_conv2, name=\"d_conv3\", filters = 16, \n",
    "                             kernel_size = 1,strides = 1,padding = \"valid\", activation = tf.nn.relu)\n",
    "d_conv4 = tf.layers.conv2d(d_conv3, name=\"d_conv4\", filters = 32, \n",
    "                             kernel_size = 1,strides = 1,padding = \"valid\", activation = tf.nn.relu)\n",
    "d_conv5 = tf.layers.conv2d(d_conv4, name=\"d_conv5\", filters = 16, \n",
    "                             kernel_size = 1,strides = 1,padding = \"valid\", activation = tf.nn.relu)\n",
    "d_conv5_flat = tf.reshape(d_conv5,[tf.shape(d_conv5)[0],d_conv5.shape[1]*d_conv5.shape[2]*d_conv5.shape[3]])\n",
    "\n",
    "dense = tf.layers.dense(d_conv5_flat,shape[0]*shape[1]*shape[2])\n",
    "output = tf.reshape(dense,[tf.shape(d_conv5_flat)[0],shape[0],shape[1],shape[2]])\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(output-Y))\n",
    "\n",
    "#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = output, labels = Y)) \n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "        \n",
    "       \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "loss_sum = tf.summary.scalar('Loss', loss)\n",
    "output_image_sum = tf.summary.image('Generated_Image',output)\n",
    "input_image_sum = tf.summary.image('Input_Image',X)\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'AutoEncoder_logs/train': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r AutoEncoder_logs/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Graph\n",
      "Starting Training\n",
      "Epoch: 1  Iteration: 162/24678 (0.7%)  Loss: 5137.17529"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 5\n",
    "n_iterations_per_epoch = 123392 // batch_size\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = \"./AutoEncoder_logs/caps_AE\"\n",
    "restore_checkpoint = False\n",
    "save = False\n",
    "tensorboard = False\n",
    "\n",
    "print(\"Loading Graph\")\n",
    "sess = tf.Session()\n",
    "if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "else:\n",
    "    sess.run(init)\n",
    "    \n",
    "train_writer = tf.summary.FileWriter('AutoEncoder_logs/train',\n",
    "                                      sess.graph)\n",
    "\n",
    "print(\"Starting Training\")\n",
    "\n",
    "step = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration,(batch) in enumerate(gen_data(batch_size,shape=shape)):\n",
    "        step+=1\n",
    "        loss_train = 0\n",
    "        _,loss_train,pred,summary = sess.run([training_op,loss,output,merged],feed_dict={X: batch,\n",
    "                       Y: batch})\n",
    "        train_writer.add_summary(summary, step)\n",
    "        print((\"\\rEpoch: {}  Iteration: {}/{} ({:.1f}%)  Loss: {:.5f}\").format(\n",
    "                      epoch+1,iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "        if save and iteration%100 == 0:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
